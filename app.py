import streamlit as st
from urllib.parse import quote
import requests
import feedparser

st.set_page_config(page_title="ğŸ“² ìˆí¼ ë‰´ìŠ¤ & ë…¼ë¬¸ & ì˜ìƒ ë·°ì–´", layout="centered")
st.title("ğŸ“² ìˆí¼ ë‰´ìŠ¤ & ë…¼ë¬¸ & ì˜ìƒ ë·°ì–´")

# API í‚¤ ì„¤ì • (ë³¸ì¸ì˜ NewsAPI í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”)
NEWS_API_KEY = "ì—¬ê¸°ì—_ë³¸ì¸ì˜_NewsAPI_í‚¤_ì…ë ¥"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "index" not in st.session_state:
    st.session_state.index = 0
if "data" not in st.session_state:
    st.session_state.data = []
if "source" not in st.session_state:
    st.session_state.source = None

# ê²€ìƒ‰ì–´ ë° ë°ì´í„° ì¶œì²˜ ì…ë ¥
query = st.text_input("ê´€ì‹¬ ìˆëŠ” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "AI")
source = st.selectbox("ë°ì´í„° ì¶œì²˜ ì„ íƒ", ["News", "arXiv Papers", "Video (URL ì§ì ‘ ì…ë ¥)"])

# ì˜ìƒ URL ì…ë ¥ (ì˜ìƒ ëª¨ë“œì¼ ë•Œë§Œ ë³´ì´ë„ë¡)
video_url = None
if source == "Video (URL ì§ì ‘ ì…ë ¥)":
    video_url = st.text_input("ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš” (ìœ íŠœë¸Œ ìˆì¸ , ë¦´ìŠ¤ ë“±)")

# ë‰´ìŠ¤ API í•¨ìˆ˜
def fetch_news(query, api_key):
    query_encoded = quote(query)
    url = f"https://newsapi.org/v2/everything?q={query_encoded}&sortBy=publishedAt&language=en&pageSize=10&apiKey={api_key}"
    response = requests.get(url)

    if response.status_code != 200:
        st.error(f"ë‰´ìŠ¤ API ì˜¤ë¥˜: {response.status_code}")
        st.error(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
        return []

    data = response.json()
    if data.get("status") != "ok":
        st.error(f"ë‰´ìŠ¤ API ì˜¤ë¥˜ ë©”ì‹œì§€: {data.get('message')}")
        return []

    return data.get("articles", [])

# arXiv API í•¨ìˆ˜
def fetch_arxiv(query, max_results=10):
    url = f"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}"
    feed = feedparser.parse(url)
    if feed.bozo:
        st.error("arXiv API íŒŒì‹± ì˜¤ë¥˜")
        return []
    return feed.entries

# ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì‹œ
if st.button("ê²€ìƒ‰ ì‹œì‘"):
    st.session_state.index = 0
    st.session_state.source = source

    if source == "News":
        st.session_state.data = fetch_news(query, NEWS_API_KEY)
    elif source == "arXiv Papers":
        st.session_state.data = fetch_arxiv(query)
    elif source == "Video (URL ì§ì ‘ ì…ë ¥)":
        if video_url:
            st.session_state.data = [video_url]
        else:
            st.error("ì˜ìƒ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
            st.session_state.data = []
    else:
        st.session_state.data = []

# ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³´ì—¬ì£¼ê¸°
if st.session_state.data:
    idx = st.session_state.index

    if st.session_state.source == "News":
        item = st.session_state.data[idx]
        st.markdown(f"### ğŸ“° {item.get('title', 'ì œëª© ì—†ìŒ')}")
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë³´ì—¬ì£¼ê¸°
        if item.get("urlToImage"):
            st.image(item["urlToImage"], use_column_width=True)
        st.write(item.get("description", "ì„¤ëª… ì—†ìŒ"))
        st.markdown(f"[ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({item.get('url', '#')})")
        st.caption(f"{item.get('source', {}).get('name', '')} | {item.get('publishedAt', '')[:10]}")

    elif st.session_state.source == "arXiv Papers":
        item = st.session_state.data[idx]
        st.markdown(f"### ğŸ“„ {item.title}")
        st.write(item.summary)
        st.markdown(f"[arXiv ì›ë¬¸ ë³´ê¸°]({item.link})")
        st.caption(", ".join([author.name for author in item.authors]))

    elif st.session_state.source == "Video (URL ì§ì ‘ ì…ë ¥)":
        video_url = st.session_state.data[0]
        st.video(video_url)

    # ì´ì „ / ë‹¤ìŒ ë²„íŠ¼
    col1, col2 = st.columns(2)
    with col1:
        if st.button("â¬… ì´ì „") and idx > 0:
            st.session_state.index -= 1
            st.experimental_rerun()
    with col2:
        if st.button("ë‹¤ìŒ â¡") and idx < len(st.session_state.data) - 1:
            st.session_state.index += 1
            st.experimental_rerun()
else:
    st.write("ê²€ìƒ‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì„¸ìš”.")
