import streamlit as st
import requests
import feedparser

# ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ShortForm ë‰´ìŠ¤/ë…¼ë¬¸ ë·°ì–´", layout="centered")
st.title("ğŸ“² ìˆí¼ ë‰´ìŠ¤ & ë…¼ë¬¸ ë·°ì–´")

# ì…ë ¥ë°›ê¸°
query = st.text_input("ê´€ì‹¬ ìˆëŠ” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "AI")
source = st.selectbox("ë°ì´í„° ì¶œì²˜:", ["News", "arXiv Papers"])

NEWS_API_KEY = "secret_key"

# News API í•¨ìˆ˜
def fetch_news(query, api_key):
    url = f"https://newsapi.org/v2/everything?q={query}&sortBy=publishedAt&language=en&pageSize=5&apiKey={api_key}"
    response = requests.get(url)
    return response.json().get("articles", [])

# arXiv API í•¨ìˆ˜
def fetch_arxiv(query, max_results=5):
    url = f"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}"
    feed = feedparser.parse(url)
    return feed.entries

# ê²€ìƒ‰ ë²„íŠ¼
if st.button("ê²€ìƒ‰ ì‹œì‘"):
    st.info(f"â€˜{query}â€™ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

    if source == "News":
        articles = fetch_news(query, NEWS_API_KEY)
        for article in articles:
            with st.expander(f"ğŸ“° {article['title']}"):
                st.write(article.get("description", "ì„¤ëª… ì—†ìŒ"))
                st.markdown(f"[ì›ë¬¸ ë§í¬]({article['url']})")
                st.caption(f"{article['source']['name']} | {article['publishedAt'][:10]}")

    elif source == "arXiv Papers":
        papers = fetch_arxiv(query)
        for paper in papers:
            with st.expander(f"ğŸ“„ {paper.title}"):
                st.write(paper.summary)
                st.markdown(f"[arXiv ë§í¬]({paper.link})")
                st.caption(", ".join([a.name for a in paper.authors]))
